{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e53bc7ef-fc1c-4737-89af-5857f71f46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline model with the minimum accuracy\n",
    "\n",
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6df1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  real_text_id\n",
      "0   0             1\n",
      "1   1             2\n",
      "2   2             1\n",
      "3   3             2\n",
      "4   4             2\n",
      "(95, 2)\n",
      "Index(['id', 'real_text_id'], dtype='object')\n",
      "id              0\n",
      "real_text_id    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# local train directory\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "# print the first 5 rows of the dataframe\n",
    "print(train_df.head())\n",
    "# print the shape of the dataframe\n",
    "print(train_df.shape)\n",
    "# print the columns of the dataframe\n",
    "print(train_df.columns)\n",
    "\n",
    "# check if there is any null data\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bcd4710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['article_0045', 'article_0042', 'article_0089', 'article_0074', 'article_0080']\n"
     ]
    }
   ],
   "source": [
    "# Load train articles \n",
    "TRAIN_DIR = 'data/train'\n",
    "FILE1_NAME = 'file_1.txt'\n",
    "FILE2_NAME = 'file_2.txt'\n",
    "train_folders = os.listdir(TRAIN_DIR)\n",
    "\n",
    "# print first 5 folders name\n",
    "print(train_folders[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c137d4ec-c961-4e72-8f5e-25dafe15a2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    2\n",
      "Name: real_text_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    " real_artical_id = train_df.loc[train_df['id'] == 3, 'real_text_id']\n",
    "print(real_artical_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26d7108-691a-4e23-9b6f-173d3e0219e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id                                          real_text  \\\n",
      "0          45  The VLT has enabled two major projects using t...   \n",
      "1          42  A key question is what causes powerful outflow...   \n",
      "2          89  The 2006 SPIE Symposium on Astronomical Telesc...   \n",
      "3          74  The primary mirror design of the European Extr...   \n",
      "4          80  The goal of this one-day workshop, part of the...   \n",
      "\n",
      "                                           fake_text  \n",
      "0  We have undertaken two major projects using th...  \n",
      "1  A burning question for us is what fuels the mo...  \n",
      "2  The 2006 SPIE Symposium on Astronomical Telesc...  \n",
      "3  The primary mirror design for the European Ext...  \n",
      "4  The goal of this one-day workshop, part of the...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# loop through sub training folders and make data frame from them\n",
    "data = []\n",
    "for folder in train_folders:\n",
    "    current_folder_path = os.path.join(TRAIN_DIR, folder)\n",
    "    # double check if target path is a vlid folder?\n",
    "    if(os.path.isdir(current_folder_path)):\n",
    "        file_1_path = os.path.join(current_folder_path, FILE1_NAME)\n",
    "        file_2_path = os.path.join(current_folder_path, FILE2_NAME)\n",
    "\n",
    "        with open(file_1_path, 'r') as f1, open(file_2_path, 'r') as f2:\n",
    "            file_1_text = f1.read()\n",
    "            file_2_text = f2.read()\n",
    "\n",
    "        regex_folder_name =  re.search(r'\\d+', folder).group()\n",
    "        article_id = int(regex_folder_name)\n",
    "        real_artical_id = train_df.loc[train_df['id'] == article_id, 'real_text_id'].values[0]\n",
    "\n",
    "        # distinguish real or fake text \n",
    "        real_text = file_1_text if real_artical_id == 1 else file_2_text\n",
    "        fake_text = file_2_text if real_artical_id == 1 else file_1_text\n",
    "\n",
    "        data.append({\n",
    "            'article_id': article_id,\n",
    "            'real_text': real_text,\n",
    "            'fake_text': fake_text\n",
    "        })\n",
    "        \n",
    "\n",
    "formated_data_df = pd.DataFrame(data)\n",
    "print(formated_data_df.head())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ea5091-11ec-4dd6-a238-f7996e15511c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# reorganize data real_text add label 1. fake add label 0. and text will be convert to vector with word2vec\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "# reorganize data real_text add label 1. fake add label 0. and text will be convert to vector with word2vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72df14-76b1-4879-8af0-d2c8fb29464f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
