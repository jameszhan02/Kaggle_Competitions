{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1852e0-6a8e-4765-b179-6cdcfd337949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb39114b-a18f-4fa9-8121-d76e5670f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data set into instance\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "337ba348-c4c4-4be0-b041-1222847f938a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "print(train_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "183a910e-324d-4812-9d5f-0596f678e212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf413e18-b9c1-4475-86ff-d04ca7641ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived\n",
      "0    549\n",
      "1    342\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data['Survived'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "813afa59-2bb9-4813-b951-fd210c1fa9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1737c75a-a598-4d1d-a035-0ac6c4cea99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# first peek only select features that intuitionlly more realte with the 'res' coause we only have 891 data to train\n",
    "# more features might bring more noise which is unnecessary.\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "X = train_data[features]\n",
    "y = train_data['Survived']\n",
    "\n",
    "# handle contionius data \n",
    "# imputer is for fill the missing/null values in the data.\n",
    "# scaler | standardScaler is convert data into N(0,1) distribution\n",
    "numerical_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# handle discrete data.\n",
    "# one hot will split diff category into diff column like [ Pclass_1 | Pclass_2 ]\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "\n",
    "# 将数据分为训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "310b89a5-9fb3-416c-bf72-72120679e309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Training Data Head:\n",
      "        Age     SibSp     Parch      Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
      "0  1.232263 -0.470722 -0.479342 -0.078684       1.0       0.0       0.0   \n",
      "1 -0.500482 -0.470722 -0.479342 -0.377145       0.0       1.0       0.0   \n",
      "2  0.192616 -0.470722 -0.479342 -0.474867       0.0       0.0       1.0   \n",
      "3 -0.269449  0.379923 -0.479342 -0.476230       0.0       0.0       1.0   \n",
      "4 -1.809667  2.931860  2.048742 -0.025249       0.0       0.0       1.0   \n",
      "\n",
      "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
      "0         0.0       1.0         0.0         0.0         1.0  \n",
      "1         0.0       1.0         0.0         0.0         1.0  \n",
      "2         0.0       1.0         0.0         0.0         1.0  \n",
      "3         0.0       1.0         0.0         0.0         1.0  \n",
      "4         1.0       0.0         0.0         0.0         1.0  \n"
     ]
    }
   ],
   "source": [
    "# for valid how preprocessor work purpose.\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "# orginal features name\n",
    "num_features_names = numerical_features\n",
    "# one hot column name\n",
    "cat_features_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "# merage all columns\n",
    "all_features_names = list(num_features_names) + list(cat_features_names)\n",
    "# create new DataFrame for display\n",
    "X_train_transformed_df = pd.DataFrame(X_train_transformed, columns=all_features_names)\n",
    "# print head of data after transform\n",
    "print(\"Transformed Training Data Head:\")\n",
    "print(X_train_transformed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5457853-ddb8-4a1e-b574-3d79c649fe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集准确率: 0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 创建逻辑回归模型\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', LogisticRegression())])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# 评估模型\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'验证集准确率: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa81a62f-cc25-45c5-8f2c-84d28bb69759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提交文件已创建！\n"
     ]
    }
   ],
   "source": [
    "# 预处理测试数据\n",
    "X_test = test_data[features]\n",
    "\n",
    "# 进行预测\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "# 准备提交文件\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': test_preds})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"提交文件已创建！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064109e6-c503-4886-a509-225dd984b688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
